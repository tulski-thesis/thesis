\abstract
The thesis focuses on web scraping --- a technique for extracting information from the Internet.
It considers it from both the perspective of conducting it and securing against it.
The theoretical basis of web scraping, its practical applications and various techniques for conducting it are presented.
Its three-stage process is described in detail: data retrieval, processing, and saving and presentation.
Special emphasis was placed on web scraping detection methods, including rate limiting of requests,
use of reverse proxies with rules to block bots, and browser fingerprinting.
The scraper and detection methods were presented as a case study, using a research platform (an online store).
The described and implemented defenses were tested in various scenarios, both individually and in their conjunction.
Attention was paid to the importance of web scraping as a tool for effective data acquisition, as well as to the essence of effective methods for its detection.
\keywords web scraping, bot detection, rate limiting, reverse proxy, browser fingerprinting