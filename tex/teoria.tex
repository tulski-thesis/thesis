\newpage

\section{Teoria związana z tematem pracy}\label{sec:teoria}

\subsection{Web Scraping}\label{subsec:web-scraping}

Web Scraping, znany również jako Web Data Extraction, Web Data Scraping, Web Harvesting i Screen scraping, to technika pozyskiwania informacji z zasobów WWW (World Wide Web)\cite{Zhao2017}.
Choć niektóre źródła dopuszczają stosowanie metod manualnych\cite{applications-and-tools}, to proces web scrapingu jest najczęściej zautomatyzowany za pomocą specjalistycznego oprogramowania.
Takie podejście umożliwia efektywne pozyskanie setek, milionów a nawet miliardów rekordów danych.

\subsection{Zastosowania Web Scrapingu}\label{subsec:web-scraping-applications}

Web scraping to jedno z najcenniejszych narzędzi w obszarze pracy z danymi, umożliwiając pozyskanie ogromnych ilości danych z niemal nieograniczonych zasobów internetu\cite{Zhao2017}.
Dzięki automatyzacji i łatwemu dostępowi do niemal nieograniczonych zasobów, metoda ta zapewnia efektywne zbieranie danych przy relatywnie niskich kosztach.
Poniżej opisano przykładowe obszary, w których stosuje się web scraping.

\subsubsection{Business Intelligence}
Web Scraping może służyć za narzędzie, które pomaga firmom w podejmowaniu świadomych decyzji biznesowych i budowaniu przewagi konkurencyjnej.
Najczęściej zbieranymi informacjami są informacje o asortymencie konkurencji, cenach, promocjach, dostępności produktów, opinie klientów oraz dane kontaktowe.
Na rynku istnieją firmy, takie jak Doubledata\cite{doubledata}, które sprzedają web scraping konkurencji w formie usługi.
Podczas przeglądania internetu i literatury, można zauważyć, że rynek e-commerce jest jednym z najczęstszych kontekstów, w którym omawiane jest zastosowanie web scrapingu.

\subsubsection{Marketing i PR}

Web Scraping odgrywa kluczową rolę w monitorowaniu treści internetowych i mediów społecznościowych, takich jak Twitter, Facebook, Instagram, LinkedIn czy YouTube.
Jest stosowany do śledzenia opinii publicznej, obserwowania trendów oraz monitorowania wzmianek o marce.
Automatyzacja tego procesu umożliwia szybką reakcję, co jest niezwykle ważne w efektywnym zarządzaniu reputacją marki\cite{monitoring-social-media}.

\subsubsection{Machine Learning i Artificial Intelligence}

Naukowcy i inżynierowie wykorzystują web scraping do pozyskiwania danych, które są niezbędne do trenowania i modeli sztucznej inteligencji\cite{openai-data-collection}.
Dane te wykorzystywane są w różnych celach, od automatycznego rozpoznawania obrazu po analizę języka naturalnego.


\subsection{Proces Web Scrapingu}\label{subsec:web-scraping-process}

Proces Web Scrapingu można podzielić na trzy główne etapy: pobieranie danych, konwersja i przetwarzanie oraz zapis i/lub prezentacja informacji\cite{persson}.

\subsubsection{Pobieranie danych}

Pierwszy etapem procesu jest pobranie danych zawierających interesujące nas treści.
Zazwyczaj realizuje się to poprzez wysłanie zapytań HTTP (ang. \emph{Hypertext Transfer Protocol}) do jednego lub wielu serwerów WWW\@.
Pobrane, surowe dane zwykle są w formacie HTML (ang. \emph{Hypertext Markup Language}), XML (ang. \emph{Extensible Markup Language}) lub JSON (ang. \emph{JavaScript Object Notation}).
To kluczowy etap z perspektywy cyberbezpieczeństwa, ponieważ to właśnie w nim scraper wchodzi w bezpośrednią interakcję z scrapowaną infrastrukturą.
W związku z zabezpieczeniami stosowanymi przez serwery, ich dostępnością, wydajnością oraz ograniczeniami sieciowymi, etap ten jest zwykle najdłuższym w całym procesie.

\subsubsection{Konwersja i przetwarzanie}

\todo{Konwersja i przetwarzanie}

\subsubsection{Zapis i/lub prezentacja informacji}

\todo{Zapis i/lub prezentacja informacji}

Głównym celem tego etapu jest przekształcenie zebranych informacji w łatwo przetwarzalne i analizowalne formaty\cite{iee-state-of-the-art}.

\subsection{Metody Web Scrapingu}\label{subsec:web-scraping-methods}
